{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c14607c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Discount Band (object)\n",
      "\n",
      "chi2: 19.200\n",
      "cv: 15.507\n",
      "p: 0.014\n",
      "Cramers V: 0.122\n",
      "\n",
      "Correlation: Small\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Units Sold (float64)\n",
      "\n",
      "chi2: 156.589\n",
      "cv: 124.342\n",
      "p: 0.000\n",
      "Cramers V: 0.237\n",
      "\n",
      "Correlation: Small\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Sale Price (int64)\n",
      "\n",
      "chi2: 1516.667\n",
      "cv: 21.026\n",
      "p: 0.000\n",
      "Cramers V: 0.852\n",
      "\n",
      "Correlation: Large\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Gross Sales (float64)\n",
      "\n",
      "chi2: 594.290\n",
      "cv: 119.871\n",
      "p: 0.000\n",
      "Cramers V: 0.462\n",
      "\n",
      "Correlation: Medium\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Discounts (float64)\n",
      "\n",
      "chi2: 331.268\n",
      "cv: 110.898\n",
      "p: 0.000\n",
      "Cramers V: 0.345\n",
      "\n",
      "Correlation: Medium\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Sales (float64)\n",
      "\n",
      "chi2: 598.481\n",
      "cv: 119.871\n",
      "p: 0.000\n",
      "Cramers V: 0.464\n",
      "\n",
      "Correlation: Medium\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: COGS (float64)\n",
      "\n",
      "chi2: 623.440\n",
      "cv: 119.871\n",
      "p: 0.000\n",
      "Cramers V: 0.473\n",
      "\n",
      "Correlation: Medium\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Test: Binned Chi-Square (Χ²) and Cramers V\n",
      "Target: Segment (object)\n",
      "Column: Profit (float64)\n",
      "\n",
      "chi2: 633.895\n",
      "cv: 106.395\n",
      "p: 0.000\n",
      "Cramers V: 0.477\n",
      "\n",
      "Correlation: Medium\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Correlation Between Target and Columns\n",
      "\n",
      "Target: Segment\n",
      "\n",
      "Large\n",
      " - Sale Price\n",
      "Medium\n",
      " - Gross Sales\n",
      " - Discounts\n",
      " - Sales\n",
      " - COGS\n",
      " - Profit\n",
      "Small\n",
      " - Discount Band\n",
      " - Units Sold\n",
      "None\n",
      " - Country\n",
      " - Product\n",
      " - Manufacturing Price\n",
      " - Month Number\n",
      " - Month Name\n",
      " - Year\n"
     ]
    }
   ],
   "source": [
    "# Program Purpose: Find Correlation between target column and all other columns. Automates statistical \n",
    "# tests of correlation as well as allows any analyst to find association between all types of variables \n",
    "# without extensive statistical experience.\n",
    "\n",
    "# First, the program takes an input of a excel file or a csv file and\n",
    "# then have the user input a target column. This target will then be compared to all of the \n",
    "# other columns through the use of statistical tests. These tests will then determine correlation\n",
    "# between the target and the columns. The program classifies each of these correlations as\n",
    "# either large, medium, small, or none. The program outputs a list of all of these correlations\n",
    "# based on the category that they were assigned. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_excel('C:/Users/Ted/Downloads/FinancialSample.xlsx')\n",
    "#df = pd.read_csv('C:/Users/Ted/Downloads/FinancialSample.csv')\n",
    "\n",
    "target = 'Segment'              # Segment and Units Sold are good test samples\n",
    "showCrosstab = False\n",
    "showBinnedCrossTab = False          # Depending on the dataset, these crosstabs can be very large and hard to understand but can still glean information from it if interested\n",
    "showGroupMeans = False             # Not working for now due to the possibility of the order of object and number to be swapped in ANOVA\n",
    "includeExplanations = False        # Not implemented\n",
    "\n",
    "correlation_categories = {\n",
    "    \"large\": [],\n",
    "    \"medium\": [],\n",
    "    \"small\": [],\n",
    "    \"none\": []\n",
    "}\n",
    "\n",
    "# for every column that is not the target column, check the dtype of that \n",
    "# column and the target column and see if they are both object\n",
    "for column in df.columns:\n",
    "    if target != column:\n",
    "        # object vs object: chi2 and Cramer's V (bias corrected)\n",
    "        # this test compares observed and expected frequencies of the crosstab\n",
    "        if df[target].dtype == 'object' and df[column].dtype == 'object':\n",
    "            ct = pd.crosstab(df[target], df[column])\n",
    "            if showCrosstab == True:\n",
    "                print(ct)\n",
    "                print()\n",
    "            \n",
    "            chi2, p, dof, expected = stats.chi2_contingency(ct)\n",
    "            critical_value = stats.chi2.ppf(1 - 0.05, dof)\n",
    "            \n",
    "            r, k = ct.shape                                      # Number of rows and columns\n",
    "            n = np.sum(ct.values) \n",
    "            k_corrected_term = ((k - 1)**2) / (n - 1)            # Bias correction terms\n",
    "            r_corrected_term = ((r - 1)**2) / (n - 1)\n",
    "            k_corrected = k - k_corrected_term                   # Corrected number of rows and columns for bias correction\n",
    "            r_corrected = r - r_corrected_term\n",
    "                    \n",
    "            if p < 0.05:\n",
    "                if chi2 > critical_value:\n",
    "                    \n",
    "                    print('Test: Chi-Square (Χ²) and Cramers V')\n",
    "                    \n",
    "                    print(f'Target: {target} ({df[target].dtype})')\n",
    "                    print(f'Column: {column} ({df[column].dtype})')\n",
    "                    print()\n",
    "                    \n",
    "                    cramers_v = np.sqrt((chi2 / n) / min(k_corrected - 1, r_corrected - 1))\n",
    "    \n",
    "                    if cramers_v > 0.5:\n",
    "                        doc = 'Large'\n",
    "                        correlation_categories[\"large\"].append(column)\n",
    "                    elif cramers_v > 0.3:\n",
    "                        doc = 'Medium'\n",
    "                        correlation_categories[\"medium\"].append(column)\n",
    "                    elif cramers_v > 0.1:\n",
    "                        doc = 'Small'\n",
    "                        correlation_categories[\"small\"].append(column)\n",
    "                    else:\n",
    "                        doc = 'None'\n",
    "                        correlation_categories[\"none\"].append(column)\n",
    "\n",
    "                    print(f'chi2: {chi2:.3f}')\n",
    "                    print(f'cv: {critical_value:.3f}')          # this is the value that chi squared must be below or above to determine if it is high or low\n",
    "                    print(f'p: {p:.3f}')\n",
    "                    print(f'Cramers V: {cramers_v:.3f}')        # note that Cramers V works but is not suited towards 2x2 contingency tables\n",
    "                    \n",
    "                    print()    \n",
    "                    print('Correlation:', doc)\n",
    "                    \n",
    "            \n",
    "                    #print('p value is below the significance threshold of 0.05')\n",
    "                    #print('chi2 value is greater than critical value')\n",
    "                    #print('the difference between observed and expected frequencies is too large to be attributed to chance')\n",
    "\n",
    "                    print()\n",
    "                    print('---------------------------------------------------------')\n",
    "                    print()\n",
    "                    \n",
    "                else: \n",
    "                    correlation_categories[\"none\"].append(column)\n",
    "                    #print('No Correlation')\n",
    "                    #print()\n",
    "                    #print('p value is above the significance threshold of 0.05')\n",
    "                    #print('chi2 value is less than critical value')\n",
    "                    #print('the difference between observed and expected frequencies is too small and could be attributed to chance')\n",
    "                    \n",
    "            else:\n",
    "                correlation_categories[\"none\"].append(column)\n",
    "                #print('No Correlation')\n",
    "                #print()\n",
    "                #print('p value is above the significance threshold of 0.05')\n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "        #numerical vs numerical: pearsons or spearmans\n",
    "        if (df[target].dtype == 'float64' or df[target].dtype == 'int64') and (df[column].dtype == 'float64' or df[column].dtype == 'int64'):\n",
    "            \n",
    "            x, p = stats.spearmanr(df[target], df[column])       # can use either pearsonr or spearmanr depending on how the data is distributed             \n",
    "            \n",
    "            if p < 0.05:\n",
    "                \n",
    "                print('Test: Spearmans Correlation Coefficient')\n",
    "                \n",
    "                if x >= 0.5:\n",
    "                    doc = 'Large Positive'\n",
    "                    correlation_categories[\"large\"].append(column)\n",
    "                elif x >= 0.3:\n",
    "                    doc = 'Medium Positive'\n",
    "                    correlation_categories[\"medium\"].append(column)\n",
    "                elif x >= 0.1:\n",
    "                    doc = 'Small Positive'\n",
    "                    correlation_categories[\"small\"].append(column)\n",
    "                elif x < 0.1 and x > -0.1:\n",
    "                    doc = 'None'\n",
    "                    correlation_categories[\"none\"].append(column)\n",
    "                elif x <= -0.1 and x > -0.3:\n",
    "                    doc = 'Small Negative'\n",
    "                    correlation_categories[\"small\"].append(column)\n",
    "                elif x <= -0.3 and x > -0.5:\n",
    "                    doc = 'Medium Negative'\n",
    "                    correlation_categories[\"medium\"].append(column)\n",
    "                elif x <= -0.5 and x >= -1:\n",
    "                    doc = 'Large Negative'\n",
    "                    correlation_categories[\"large\"].append(column)\n",
    "\n",
    "                print(f'Target: {target} ({df[target].dtype})')\n",
    "                print(f'Column: {column} ({df[column].dtype})')\n",
    "                print()\n",
    "\n",
    "                print(f'x: {x:.3f}')\n",
    "                print(f'p: {p:.3f}')\n",
    "\n",
    "                print()\n",
    "                \n",
    "                print('Correlation:', doc)\n",
    "                #print('p value is below the significance threshold of 0.05')    \n",
    "                \n",
    "                print()\n",
    "                print('---------------------------------------------------------')\n",
    "                print()\n",
    "                \n",
    "            else:\n",
    "                correlation_categories[\"none\"].append(column)\n",
    "                #print('No Correlation')\n",
    "                #print('Reason: p value is above the significance threshold of 0.05')\n",
    "              \n",
    "\n",
    "            \n",
    "            \n",
    "        #numerical vs object: ANOVA\n",
    "        #There can be no technical 'correlation' between numerical vs categorical, only the result is something very similar \n",
    "        if ((df[target].dtype == 'float64' or df[target].dtype == 'int64') and df[column].dtype == 'object'):    \n",
    "            \n",
    "            grouped_data = df.groupby(column)[target].apply(list)\n",
    "\n",
    "            # Convert the grouped data into a list of arrays suitable for ANOVA\n",
    "            data_arrays = [group for group in grouped_data]\n",
    "\n",
    "            #print(*data_arrays)\n",
    "            #print(grouped_data)\n",
    "            #print(grouped_data)\n",
    "                \n",
    "            # Perform ANOVA\n",
    "            f, p = stats.f_oneway(*data_arrays)\n",
    "            n = len(df.index)        # number of rows\n",
    "            # Finding degrees of freedom for both numerator and demoninator, then using those to help find critical value\n",
    "            dfn, dfd = (len(grouped_data) - 1), (n - 2)      # (2-1) because we are only comparing 2 groups, len(df.index) is number of rows\n",
    "            critical_value = stats.f.ppf(1 - 0.05, dfn, dfd)\n",
    "            \n",
    "            \n",
    "            if p < 0.05:\n",
    "                if f > critical_value:\n",
    "                    \n",
    "                    print('Test: ANOVA and Eta-Squared (η²)')\n",
    "                    \n",
    "                    # Calculating the 3 values here that are needed to find the eta^2\n",
    "                    # Calculate Total Sum of Squares (TSS)  \n",
    "                    # all_data = np.concatenate(grouped_data)\n",
    "                    all_data = []\n",
    "                    for group in grouped_data:\n",
    "                        all_data.extend(group)\n",
    "                    all_data = np.array(all_data)\n",
    "                    grand_mean = np.mean(all_data)\n",
    "                    tss = np.sum((all_data - grand_mean) ** 2)\n",
    "\n",
    "                    # Calculate Within-Group Sum of Squares (WSS)\n",
    "                    wss = sum(sum((group - np.mean(group)) ** 2) for group in grouped_data)\n",
    "\n",
    "                    # Calculate Between-Group Sum of Squares (BSS)\n",
    "                    bss = tss - wss\n",
    "\n",
    "                    # Calculate Eta-squared (η²)\n",
    "                    eta_squared = bss / tss\n",
    "                    \n",
    "                    if eta_squared > 0.14:\n",
    "                        doc = 'Large'\n",
    "                        correlation_categories[\"large\"].append(column)\n",
    "                    elif eta_squared > 0.06:\n",
    "                        doc = 'Medium'\n",
    "                        correlation_categories[\"medium\"].append(column)\n",
    "                    elif eta_squared > 0.01:\n",
    "                        doc = 'Small'\n",
    "                        correlation_categories[\"small\"].append(column)\n",
    "                    else:\n",
    "                        doc = 'None'\n",
    "                        correlation_categories[\"none\"].append(column)\n",
    "                        \n",
    "                    print(f'Target: {target} ({df[target].dtype})')\n",
    "                    print(f'Column: {column} ({df[column].dtype})')\n",
    "                    \n",
    "                    if showGroupMeans == True:\n",
    "                        print()\n",
    "                        print('Table of Means by Each Group')\n",
    "                        print()\n",
    "                        group_means = df.groupby(column)[target].mean().reset_index()\n",
    "                        print(round(group_means, 2))\n",
    "                    \n",
    "                    print()\n",
    "                    print(f\"f: {f:.3f}\")\n",
    "                    print(f\"cv: {critical_value:.3f}\", )\n",
    "                    print(f\"p: {p:.3f}\")\n",
    "                    print(f\"Eta-Squared: {eta_squared:.3f}\")     \n",
    "                    print()\n",
    "                    \n",
    "                    print('Correlation:', doc)\n",
    "                    \n",
    "                    print()\n",
    "                    #print('p value is below the significance threshold of 0.05')\n",
    "                    #print('f value is greater than critical value')\n",
    "                    #print('the difference between observed and expected frequencies is too large to be attributed to chance')\n",
    "\n",
    "                    print('---------------------------------------------------------')\n",
    "                    print()    \n",
    "                    \n",
    "                else:\n",
    "                    correlation_categories[\"none\"].append(column)\n",
    "                    #print('No Correlation')\n",
    "                    #print()\n",
    "                    #print('p value is above the significance threshold of 0.05')\n",
    "                    #print('f value is less than critical value')\n",
    "                    #print('the difference between observed and expected frequencies is too small and could be attributed to chance')\n",
    "                    \n",
    "            else:\n",
    "                correlation_categories[\"none\"].append(column)\n",
    "                #print('No Correlation')\n",
    "                #print()\n",
    "                #print('p value is above the significance threshold of 0.05')\n",
    "                \n",
    "                \n",
    "                \n",
    "        # using chi2 test, however I use bins that separate the numerical variable into a calculated number of bins\n",
    "        # finding correlation between dependent categorical variable and independent continuous variable is quite\n",
    "        # hard, and using chi2 with bins has been the most reasonable approach that I have been able to find\n",
    "        if (df[target].dtype == 'object' and (df[column].dtype == 'float64' or df[column].dtype == 'int64')):\n",
    "            \n",
    "            bins = int(np.sqrt(len(df[target])))\n",
    "            ct = pd.crosstab(df[target], pd.cut(df[column], bins), margins=False)\n",
    "            if showCrosstab == True:\n",
    "                print(ct)\n",
    "                print()\n",
    "            \n",
    "            chi2, p, dof, expected = stats.chi2_contingency(ct)\n",
    "            critical_value = stats.chi2.ppf(1 - 0.05, dof)\n",
    "            \n",
    "            r, k = ct.shape                                      # Number of rows and columns\n",
    "            n = np.sum(ct.values) \n",
    "            k_corrected_term = ((k - 1)**2) / (n - 1)            # Bias correction terms\n",
    "            r_corrected_term = ((r - 1)**2) / (n - 1)\n",
    "            k_corrected = k - k_corrected_term                   # Corrected number of rows and columns for bias correction\n",
    "            r_corrected = r - r_corrected_term\n",
    "                    \n",
    "            if p < 0.05:\n",
    "                if chi2 > critical_value:\n",
    "                    \n",
    "                    print('Test: Binned Chi-Square (Χ²) and Cramers V')\n",
    "                    \n",
    "                    print(f'Target: {target} ({df[target].dtype})')\n",
    "                    print(f'Column: {column} ({df[column].dtype})')\n",
    "                    print()\n",
    "                    \n",
    "                    cramers_v = np.sqrt((chi2 / n) / min(k_corrected - 1, r_corrected - 1))\n",
    "    \n",
    "                    if cramers_v > 0.5:\n",
    "                        doc = 'Large'\n",
    "                        correlation_categories[\"large\"].append(column)\n",
    "                    elif cramers_v > 0.3:\n",
    "                        doc = 'Medium'\n",
    "                        correlation_categories[\"medium\"].append(column)\n",
    "                    elif cramers_v > 0.1:\n",
    "                        doc = 'Small'\n",
    "                        correlation_categories[\"small\"].append(column)\n",
    "                    else:\n",
    "                        doc = 'None'\n",
    "                        correlation_categories[\"none\"].append(column)\n",
    "\n",
    "                    print(f'chi2: {chi2:.3f}')\n",
    "                    print(f'cv: {critical_value:.3f}')          # this is the value that chi squared must be below or above to determine if it is high or low\n",
    "                    print(f'p: {p:.3f}')\n",
    "                    print(f'Cramers V: {cramers_v:.3f}')        # note that Cramers V works but is not suited towards 2x2 contingency tables\n",
    "                    \n",
    "                    print()    \n",
    "                    print('Correlation:', doc)\n",
    "\n",
    "                    print()\n",
    "                    print('---------------------------------------------------------')\n",
    "                    print()\n",
    "                    \n",
    "                else: \n",
    "                    correlation_categories[\"none\"].append(column)\n",
    "\n",
    "            else:\n",
    "                correlation_categories[\"none\"].append(column)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "print('Correlation Between Target and Columns')\n",
    "print()\n",
    "print('Target:', target)\n",
    "print()\n",
    "    \n",
    "# printing out the values in each category\n",
    "for category, values in correlation_categories.items():\n",
    "    if values:\n",
    "        print(category.capitalize())\n",
    "        for value in values:\n",
    "            print(f\" - {value}\")\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
