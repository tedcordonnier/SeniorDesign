{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35524d16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Country\n",
      "Column: Segment\n",
      "\n",
      "chi2: 0.0\n",
      "Critical Value: 26.29622760486423\n",
      "p: 1.0\n",
      "Cramers V: 0.0\n",
      "\n",
      "Conclusion:\n",
      "No Correlation\n",
      "\n",
      "p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Country\n",
      "Column: Product\n",
      "\n",
      "chi2: 1.5490875905924106\n",
      "Critical Value: 31.410432844230918\n",
      "p: 0.9999999893873489\n",
      "Cramers V: 0.0235211727613382\n",
      "\n",
      "Conclusion:\n",
      "No Correlation\n",
      "\n",
      "p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Country\n",
      "Column: Discount Band\n",
      "\n",
      "chi2: 9.790481984934937\n",
      "Critical Value: 21.02606981748307\n",
      "p: 0.6343356489351766\n",
      "Cramers V: 0.06827982336342447\n",
      "\n",
      "Conclusion:\n",
      "No Correlation\n",
      "\n",
      "p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Country\n",
      "Column: Month Name\n",
      "\n",
      "chi2: 0.0\n",
      "Critical Value: 60.480886582336446\n",
      "p: 1.0\n",
      "Cramers V: 0.0\n",
      "\n",
      "Conclusion:\n",
      "No Correlation\n",
      "\n",
      "p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_excel('C:/Users/Ted/Downloads/FinancialSample.xlsx')\n",
    "#df = pd.read_csv('C:/Users/Ted/Downloads/FinancialSample.csv')\n",
    "\n",
    "target = 'Country'\n",
    "showCrosstab = False\n",
    "\n",
    "\n",
    "# for every column that is not the target column, check the dtype of that \n",
    "# column and the target column and see if they are both object\n",
    "for column in df.columns:\n",
    "    if target != column:\n",
    "        #object vs object: chi2\n",
    "        # this test compares observed and expected frequencies of the crosstab\n",
    "        if df[target].dtype == 'object' and df[column].dtype == 'object':\n",
    "            print(f'Target: {target}')\n",
    "            print(f'Column: {column}')\n",
    "            print()\n",
    "            ct = pd.crosstab(df[target], df[column])\n",
    "            if showCrosstab == True:\n",
    "                print(ct)\n",
    "                print()\n",
    "            \n",
    "            chi2, p, dof, expected = stats.chi2_contingency(ct)\n",
    "            critical_value = stats.chi2.ppf(1 - 0.05, dof)\n",
    "            \n",
    "            n = np.sum(ct.values) \n",
    "            v = np.sqrt(chi2 / (n * (min(ct.shape) - 1)))\n",
    "            \n",
    "            print(f'chi2: {chi2}')\n",
    "            print(f'Critical Value: {critical_value}')          # this is the value that chi squared must be below or above to determine if it is high or low\n",
    "            print(f'p: {p}')\n",
    "            \n",
    "            \n",
    "            \n",
    "            #move to only calculate for correlation, but I need new data in order to have correlaton examples\n",
    "            print(f'Cramers V: {v}')            # note that Cramers V works but is not suited towards 2x2 contingency tables\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            print()\n",
    "            print('Conclusion:')\n",
    "            \n",
    "            if p < 0.05:\n",
    "                if chi2 > critical_value:\n",
    "                    print('Correlation')\n",
    "                    print()\n",
    "                    print('p value is below the significance threshold of 0.05')\n",
    "                    print('chi2 value is greater than critical value')\n",
    "                    print('the difference between observed and expected frequencies is too large to be attributed to chance')\n",
    "\n",
    "                else: \n",
    "                    print('No Correlation')\n",
    "                    print()\n",
    "                    print('p value is above the significance threshold of 0.05')\n",
    "                    print('chi2 value is less than critical value')\n",
    "                    print('the difference between observed and expected frequencies is too small and could be attributed to chance')\n",
    "                    \n",
    "            else:\n",
    "                print('No Correlation')\n",
    "                print()\n",
    "                print('p value is above the significance threshold of 0.05')\n",
    "            \n",
    "            print()\n",
    "            print('---------------------------------------------------------')\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19580ac3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Units Sold\n",
      "Column: Manufacturing Price\n",
      "\n",
      "x: -0.029643972853024458\n",
      "p: 0.4335823652264368\n",
      "\n",
      "No Correlation\n",
      "Reason: p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Sale Price\n",
      "\n",
      "x: -0.0650658134215006\n",
      "p: 0.0853913408043615\n",
      "\n",
      "No Correlation\n",
      "Reason: p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Gross Sales\n",
      "\n",
      "x: 0.32722066254045745\n",
      "p: 6.232960229375536e-19\n",
      "\n",
      "Correlation\n",
      "p value is below the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Discounts\n",
      "\n",
      "x: 0.2530479774656188\n",
      "p: 1.0911815841023358e-11\n",
      "\n",
      "Correlation\n",
      "p value is below the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Sales\n",
      "\n",
      "x: 0.3269139725274527\n",
      "p: 6.747469128497393e-19\n",
      "\n",
      "Correlation\n",
      "p value is below the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: COGS\n",
      "\n",
      "x: 0.33169439250128174\n",
      "p: 1.9397416204430017e-19\n",
      "\n",
      "Correlation\n",
      "p value is below the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Profit\n",
      "\n",
      "x: 0.2284369068302451\n",
      "p: 9.7107456560683e-10\n",
      "\n",
      "Correlation\n",
      "p value is below the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Month Number\n",
      "\n",
      "x: -0.10360689389535777\n",
      "p: 0.006075681541677351\n",
      "\n",
      "Correlation\n",
      "p value is below the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "Target: Units Sold\n",
      "Column: Year\n",
      "\n",
      "x: 0.06385657739371733\n",
      "p: 0.09137475522464007\n",
      "\n",
      "No Correlation\n",
      "Reason: p value is above the significance threshold of 0.05\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_excel('C:/Users/Ted/Downloads/FinancialSample.xlsx')\n",
    "#df = pd.read_csv('C:/Users/Ted/Downloads/FinancialSample.csv')\n",
    "\n",
    "target = 'Units Sold'\n",
    "\n",
    "# for every column that is not the target column, check the dtype of that \n",
    "# column and the target column and see if they are both object\n",
    "for column in df.columns:\n",
    "    if target != column: \n",
    "        #numerical vs numerical: pearsons or spearmans\n",
    "        if (df[target].dtype == 'float64' or df[target].dtype == 'int64') and (df[column].dtype == 'float64' or df[column].dtype == 'int64'):\n",
    "            x, p = stats.pearsonr(df[target], df[column])       # can use either pearsonr or spearmanr depending on how the data is distributed\n",
    "            print(f'Target: {target}')\n",
    "            print(f'Column: {column}')\n",
    "            print()\n",
    "            \n",
    "            print(f'x: {x}')\n",
    "            print(f'p: {p}')\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            if p < 0.05:\n",
    "                print('Correlation')\n",
    "                print('p value is below the significance threshold of 0.05')    \n",
    "            else:\n",
    "                print('No Correlation')\n",
    "                print('Reason: p value is above the significance threshold of 0.05')\n",
    "            \n",
    "            print()\n",
    "            print('---------------------------------------------------------')\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b235d415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Sales\n",
      "Column: Segment\n",
      "\n",
      "Table of Means by Each Group\n",
      "\n",
      "            Segment      Sales\n",
      "0  Channel Partners   18005.94\n",
      "1        Enterprise  196116.94\n",
      "2        Government  175014.20\n",
      "3         Midmarket   23818.83\n",
      "4    Small Business  424279.18\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pingouin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m dfn, dfd \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), (n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)      \u001b[38;5;66;03m# (2-1) because we are only comparing 2 groups, len(df.index) is number of rows\u001b[39;00m\n\u001b[0;32m     42\u001b[0m critical_value \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mppf(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.05\u001b[39m, dfn, dfd)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpingouin\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpg\u001b[39;00m\n\u001b[0;32m     46\u001b[0m aov \u001b[38;5;241m=\u001b[39m pg\u001b[38;5;241m.\u001b[39manova(data\u001b[38;5;241m=\u001b[39mdf, dv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScores\u001b[39m\u001b[38;5;124m'\u001b[39m, between\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m, detailed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(aov)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pingouin'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_excel('C:/Users/Ted/Downloads/FinancialSample.xlsx')\n",
    "#df = pd.read_csv('C:/Users/Ted/Downloads/FinancialSample.csv')\n",
    "\n",
    "target = 'Sales'\n",
    "showGroupMeans = True\n",
    "\n",
    "# for every column that is not the target column, check the dtype of that \n",
    "# column and the target column and see if they are both object\n",
    "for column in df.columns:\n",
    "    if target != column: \n",
    "        #object vs numerical: ANOVA\n",
    "        #There can be no correlation between nominal vs numerical, only something similar \n",
    "        if (df[target].dtype == 'object' and (df[column].dtype == 'float64' or df[column].dtype == 'int64')) or ((df[target].dtype == 'float64' or df[target].dtype == 'int64') and df[column].dtype == 'object'):    \n",
    "            \n",
    "            print(f'Target: {target}')\n",
    "            print(f'Column: {column}')  \n",
    "            \n",
    "            if df[target].dtype == 'object':\n",
    "                grouped_data = df.groupby(target)[column].apply(list)\n",
    "            else:\n",
    "                grouped_data = df.groupby(column)[target].apply(list)\n",
    "\n",
    "            # Convert the grouped data into a list of arrays suitable for ANOVA\n",
    "            data_arrays = [group for group in grouped_data]\n",
    "\n",
    "            if showGroupMeans == True:\n",
    "                print()\n",
    "                print('Table of Means by Each Group')\n",
    "                print()\n",
    "                group_means = df.groupby(column)[target].mean().reset_index()\n",
    "                print(round(group_means, 2))\n",
    "\n",
    "            # Perform ANOVA\n",
    "            f, p = stats.f_oneway(*data_arrays)\n",
    "            n = len(df.index)        # number of rows\n",
    "            # Finding degrees of freedom for both numerator and demoninator, then using those to help find critical value\n",
    "            dfn, dfd = (2-1), (n-2)      # (2-1) because we are only comparing 2 groups, len(df.index) is number of rows\n",
    "            critical_value = stats.f.ppf(1 - 0.05, dfn, dfd)\n",
    "            \n",
    "            print()\n",
    "            print(\"f:\", f)\n",
    "            print(f\"Critical Value: {critical_value}\", )\n",
    "            print(\"p:\", p)\n",
    "            print()\n",
    "            \n",
    "            if p < 0.05:\n",
    "                if f > critical_value:\n",
    "                    print('Correlation')\n",
    "                    print()\n",
    "                    print('p value is below the significance threshold of 0.05')\n",
    "                    print('f value is greater than critical value')\n",
    "                    print('the difference between observed and expected frequencies is too large to be attributed to chance')\n",
    "\n",
    "                else: \n",
    "                    print('No Correlation')\n",
    "                    print()\n",
    "                    print('p value is above the significance threshold of 0.05')\n",
    "                    print('f value is less than critical value')\n",
    "                    print('the difference between observed and expected frequencies is too small and could be attributed to chance')\n",
    "                    \n",
    "            else:\n",
    "                print('No Correlation')\n",
    "                print()\n",
    "                print('p value is above the significance threshold of 0.05')\n",
    "            \n",
    "            print()\n",
    "            print('---------------------------------------------------------')\n",
    "            print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32ef6b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Country\n",
      "Column: Date\n",
      "Anything vs datetime\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_excel('C:/Users/Ted/Downloads/FinancialSample.xlsx')\n",
    "#df = pd.read_csv('C:/Users/Ted/Downloads/FinancialSample.csv')\n",
    "\n",
    "target = 'Country'\n",
    "\n",
    "# for every column that is not the target column, check the dtype of that \n",
    "# column and the target column and see if they are both object\n",
    "for column in df.columns:\n",
    "    if target != column:       \n",
    "        #anything vs datetime: Time Series Analysis\n",
    "        if (df[target].dtype == 'object' or df[target].dtype == 'float64' or df[target].dtype == 'int64') and df[column].dtype == 'datetime64[ns]':\n",
    "        #or df[target].dtype == 'datetime64[ns]' and (df[column].dtype == 'object' or df[column].dtype == 'float64' or df[column].dtype == 'int64')\n",
    "            \n",
    "            print(f'Target: {target}')\n",
    "            print(f'Column: {column}')  \n",
    "            print('Anything vs datetime')\n",
    "            # need to add analysis, maybe graph, summary statistics, crosstab, etc?\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c65c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "object - Segment\n",
      "object - Country\n",
      "object - Product\n",
      "object - Discount Band\n",
      "float64 - Units Sold\n",
      "int64 - Manufacturing Price\n",
      "int64 - Sale Price\n",
      "float64 - Gross Sales\n",
      "float64 - Discounts\n",
      "float64 - Sales\n",
      "float64 - COGS\n",
      "float64 - Profit\n",
      "datetime64[ns] - Date\n",
      "int64 - Month Number\n",
      "object - Month Name\n",
      "int64 - Year\n"
     ]
    }
   ],
   "source": [
    "# can change this to report words back such as categorical variable, then move this to the beginning as well as\n",
    "# combine it with summary statistics\n",
    "\n",
    "print()\n",
    "for column in df.columns:\n",
    "    print(f'{df[column].dtype} - {column}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a9311d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ct = pd.crosstab(df['Country'], df['Product'])\n",
    "#print(ct)\n",
    "#print()\n",
    "\n",
    "#stat, p, dof, expected = stats.chi2_contingency(ct)\n",
    "#critical_value = stats.chi2.ppf(1 - 0.05, dof)\n",
    "\n",
    "#print(stat)\n",
    "#print(critical_value)          # this is the value that chi squared must be below or above to determine if it is high or low\n",
    "#print(p)\n",
    "\n",
    "\n",
    "#tvar = df[target]           # target variable\n",
    "\n",
    "\n",
    "#res = stats.spearmanr(x, y)\n",
    "#print(res)\n",
    "\n",
    "\n",
    "\n",
    "#segment_data = df['Segment']\n",
    "#sales_data = df['Sales']\n",
    "#gross_sales_data = df['Gross Sales']\n",
    "\n",
    "\n",
    "#f_value, p_value = stats.f_oneway(segment_data, sales_data, gross_sales_data)\n",
    "#f_value, p_value = stats.f_oneway(df['Segment'], df['Sales'], df['Gross Sales'])\n",
    "#print(\"F-value:\", f_value, \"P-value:\", p_value)\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#import scipy.stats\n",
    "\n",
    "#x = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "#y = np.array([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "\n",
    "#scipy.stats.pearsonr(x, y)    # Pearson's r\n",
    "#scipy.stats.spearmanr(x, y)   # Spearman's rho\n",
    "#scipy.stats.kendalltau(x, y)  # Kendall's tau\n",
    "\n",
    "\n",
    "#out = scipy.stats.spearmanr(x, y)\n",
    "#print(out)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c73db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features based on chi-squared test: ['X2', 'X3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Sample DataFrame with categorical features\n",
    "data = {'X1': [1, 2, 3, 4, 5],\n",
    "        'X2': [5, 4, 3, 2, 1],\n",
    "        'X3': [2, 3, 4, 5, 6],\n",
    "        'y': [1, 0, 1, 0, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# Apply SelectKBest with chi-squared test\n",
    "k = 2  # Number of top features to select\n",
    "chi2_selector = SelectKBest(chi2, k=k)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = [X.columns[i] for i in chi2_selector.get_support(indices=True)]\n",
    "\n",
    "# Results\n",
    "print(\"Selected features based on chi-squared test:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806981af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
